"""
G≈Ç√≥wny modu≈Ç serwera Ollama.

Zawiera aplikacjƒô Flask, kt√≥ra obs≈Çuguje zapytania API i udostƒôpnia interfejs web.
"""

import logging
import os
from flask import Flask, render_template, jsonify, request, redirect, url_for
from .config import load_config
from .models import OllamaClient
from .api import api_bp

# Konfiguracja logowania
logger = logging.getLogger("ollama_server")


def create_app(config_path=None):
    """
    Tworzy i konfiguruje aplikacjƒô Flask.

    Args:
        config_path: ≈öcie≈ºka do pliku konfiguracyjnego .env

    Returns:
        Aplikacja Flask.
    """
    app = Flask(__name__, static_folder="web/static", template_folder="web/templates")

    # ≈Åadowanie konfiguracji
    config = load_config(config_path)
    app.config.update(config)

    # Rejestracja blueprint√≥w
    app.register_blueprint(api_bp)

    # Inicjalizacja klienta Ollama
    client = OllamaClient(app.config["OLLAMA_URL"])

    # Podstawowe trasy
    @app.route("/")
    def index():
        """G≈Ç√≥wna strona z interfejsem webowym."""
        # Sprawd≈∫ dostƒôpno≈õƒá serwera Ollama
        ollama_available = client.check_availability()

        # Pobierz informacje o aktualnym modelu
        model_name = app.config["MODEL_NAME"]
        model_available = False

        if ollama_available:
            model_available = client.check_model_availability(model_name.split(":")[0])

        return render_template(
            "index.html",
            config=app.config,
            ollama_available=ollama_available,
            model_available=model_available
        )

    @app.route("/ask", methods=["POST"])
    def ask():
        """
        Endpoint do zadawania pyta≈Ñ z interfejsu webowego.
        Przekierowuje zapytanie do API.
        """
        prompt = request.form.get("prompt")
        temperature = float(request.form.get("temperature", app.config["TEMPERATURE"]))
        max_tokens = int(request.form.get("max_tokens", app.config["MAX_TOKENS"]))

        if not prompt:
            return jsonify({"error": "Brak wymaganego pola 'prompt'"}), 400

        from .api import ask as api_ask
        # Modyfikacja request.json dla API
        request.json = {
            "prompt": prompt,
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        return api_ask()

    @app.route("/models")
    def models():
        """
        Endpoint do pobierania listy modeli.
        Przekierowuje zapytanie do API.
        """
        from .api import list_models as api_list_models
        return api_list_models()

    @app.route("/echo", methods=["POST"])
    def echo():
        """
        Endpoint echo do testowania serwera.
        Przekierowuje zapytanie do API.
        """
        message = request.form.get("message") or request.json.get("message")
        if not message:
            return jsonify({"error": "Brak wymaganego pola 'message'"}), 400

        # Modyfikacja request.json dla API
        request.json = {"message": message}
        from .api import echo as api_echo
        return api_echo()

    @app.route("/health")
    def health():
        """
        Endpoint sprawdzajƒÖcy zdrowie serwera.

        Returns:
            JSON ze statusem serwera i komponent√≥w.
        """
        status = {
            "server": "ok",
            "ollama": "unknown"
        }

        # Sprawd≈∫ dostƒôpno≈õƒá Ollama
        ollama_available = client.check_availability()
        status["ollama"] = "ok" if ollama_available else "unreachable"

        # Sprawd≈∫ dostƒôpno≈õƒá modelu
        if ollama_available:
            model_name = app.config["MODEL_NAME"]
            model_available = client.check_model_availability(model_name.split(":")[0])
            status["model"] = "ok" if model_available else "unavailable"
            status["model_name"] = model_name

        # Ustaw kod statusu
        http_status = 200 if status["ollama"] == "ok" else 503

        return jsonify(status), http_status

    @app.route("/switch_model", methods=["POST"])
    def switch_model():
        """
        Endpoint do prze≈ÇƒÖczania modelu.

        Returns:
            Przekierowanie do strony g≈Ç√≥wnej lub odpowied≈∫ JSON.
        """
        model_name = request.form.get("model_name")
        if not model_name:
            return jsonify({"error": "Brak wymaganego pola 'model_name'"}), 400

        # U≈ºyj endpointu API do prze≈ÇƒÖczenia modelu
        from .api import switch_model as api_switch_model
        request.json = {"model_name": model_name, "pull_if_missing": True}
        result = api_switch_model()

        # Sprawd≈∫ format odpowiedzi
        if request.headers.get("X-Requested-With") == "XMLHttpRequest":
            return result
        else:
            # Je≈õli nie jest to ≈ºƒÖdanie AJAX, przekieruj na stronƒô g≈Ç√≥wnƒÖ
            return redirect(url_for("index"))

    # Obs≈Çuga b≈Çƒôd√≥w
    @app.errorhandler(404)
    def page_not_found(e):
        return render_template("error.html", error="Nie znaleziono strony"), 404

    @app.errorhandler(500)
    def internal_server_error(e):
        return render_template("error.html", error="Wewnƒôtrzny b≈ÇƒÖd serwera"), 500

    return app


def run_server(host="0.0.0.0", port=None, debug=False, config_path=None):
    """
    Uruchamia serwer Flask.

    Args:
        host: Host nas≈Çuchiwania
        port: Port nas≈Çuchiwania (domy≈õlnie: z konfiguracji)
        debug: Czy uruchomiƒá w trybie debug
        config_path: ≈öcie≈ºka do pliku konfiguracyjnego .env
    """
    app = create_app(config_path)

    if port is None:
        port = app.config["SERVER_PORT"]

    if debug is None:
        debug = app.config.get("DEBUG", False)

    # Wy≈õwietl informacje o uruchomieniu
    model_name = app.config["MODEL_NAME"]
    ollama_url = app.config["OLLAMA_URL"]

    print(f"üöÄ Uruchamianie serwera Ollama...")
    print(f"üìÑ Konfiguracja:")
    print(f"  - Model: {model_name}")
    print(f"  - URL Ollama: {ollama_url}")
    print(f"  - Port serwera: {port}")
    print(f"  - Temperatura: {app.config['TEMPERATURE']}")
    print(f"  - Max token√≥w: {app.config['MAX_TOKENS']}")

    # Sprawd≈∫ dostƒôpno≈õƒá Ollama
    client = OllamaClient(ollama_url)
    if client.check_availability():
        print(f"‚úÖ Ollama dzia≈Ça poprawnie")

        # Sprawd≈∫ dostƒôpno≈õƒá modelu
        if client.check_model_availability(model_name.split(":")[0]):
            print(f"‚úÖ Model {model_name} jest dostƒôpny")
        else:
            print(f"‚ö†Ô∏è Model {model_name} nie jest dostƒôpny")
            print(f"   Mo≈ºesz pobraƒá model komendƒÖ: ollama pull {model_name}")
    else:
        print(f"‚ö†Ô∏è Serwer Ollama nie jest dostƒôpny")
        print(f"   Uruchom Ollama komendƒÖ: ollama serve")

    print(f"üîå Uruchamianie serwera na porcie {port}...")
    print(f"‚ÑπÔ∏è Dostƒôpne endpointy: /, /ask, /models, /echo")
    print(f"üìù Interfejs web: http://localhost:{port}")

    # Uruchom serwer
    app.run(host=host, port=port, debug=debug)


if __name__ == "__main__":
    run_server()